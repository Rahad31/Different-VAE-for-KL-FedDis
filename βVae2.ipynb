{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEu/Mb4iwBqq3aspoINZau",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahad31/Different-VAE-for-KL-FedDis/blob/main/%CE%B2Vae2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McbpNS0ya3aP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34hGoqpxKY7G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yELruI1IpCqt",
        "outputId": "d1a23ccb-4914-4dfd-94bb-0ff83ab29d81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 6.65 s, sys: 733 ms, total: 7.38 s\n",
            "Wall time: 14.3 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch import nn\n",
        "from typing import Dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WoJ24tiipdHG"
      },
      "outputs": [],
      "source": [
        "# Define VAE model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        self.x_dim = x_dim\n",
        "        self.h_dim = h_dim\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, stride=2, padding=1),  # 16x16\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2, padding=1),  # 8x8\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # 4x4\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2048, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2*z_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (128, 4, 4)),\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # 8x8\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),  # 16x16\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),  # 32x32\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h[:, :self.z_dim], h[:, self.z_dim:]\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uEU_HGlkpjMy"
      },
      "outputs": [],
      "source": [
        "def vae_train(vae: VAE, trainloader: DataLoader, epochs: int, beta: float = 0.5) -> None:\n",
        "    optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
        "    for epoch in range(epochs):\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, _ = data\n",
        "            optimizer.zero_grad()\n",
        "            recon_x, mu, logvar = vae(inputs)\n",
        "            loss = vae_loss(recon_x, inputs, mu, logvar, beta=beta)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "77xTShYPp7Tp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define classification model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LIMyvsHZqA0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870bc1e4-685c-4a8e-bc26-a613e4274531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:01<00:00, 105MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Load CIFAR10 dataset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "full_dataset = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_set = CIFAR10(root=\"./data\", train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HBc6iayKqMoT"
      },
      "outputs": [],
      "source": [
        "# Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_set, val_set = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "D1qRZ4OgqQkh"
      },
      "outputs": [],
      "source": [
        "# Create training and validation loaders\n",
        "trainloader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "testloader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-I3RRdp7qwie"
      },
      "outputs": [],
      "source": [
        "def vae_loss(recon_x, x, mu, logvar, beta=0.5):\n",
        "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + beta * KLD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "vv4Dbvl2q2za"
      },
      "outputs": [],
      "source": [
        "# Define training procedure for classification model\n",
        "def train(net: nn.Module, trainloader: DataLoader, valloader: DataLoader, epochs: int) -> None:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training loop\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation loop\n",
        "        net.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in valloader:\n",
        "                images, labels = data\n",
        "                outputs = net(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(net.state_dict(), 'best_model.pth')\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss / (i+1):.3f}, Validation Accuracy: {val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IoIsl09zq76r"
      },
      "outputs": [],
      "source": [
        "# Define evaluation procedure\n",
        "def evaluate(net: nn.Module, testloader: DataLoader) -> float:\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Z4_GLIx3rL3l"
      },
      "outputs": [],
      "source": [
        "def initialize_clients(trainset, transform, batch_size, num_clients):\n",
        "    clients = {}\n",
        "    for i in range(num_clients):\n",
        "        client_trainset = torch.utils.data.Subset(trainset, range(i * len(trainset) // num_clients, (i + 1) * len(trainset) // num_clients))\n",
        "        client_trainloader = torch.utils.data.DataLoader(client_trainset, batch_size=batch_size, shuffle=True)\n",
        "        clients[f\"client_{i}\"] = client_trainloader\n",
        "    return clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "iYhcZLZDrR6I"
      },
      "outputs": [],
      "source": [
        "def get_distribution_info(vae: VAE) -> Dict:\n",
        "    # Implement the logic to extract distribution information from the VAE\n",
        "    # This can involve computing statistics, parameters, or any other relevant information\n",
        "    # that can be used to generate augmented data\n",
        "\n",
        "    # Example implementation:\n",
        "    distribution_info = {\n",
        "        \"mean\": vae.encoder[-1].bias.data.cpu().numpy(),\n",
        "        \"std\": torch.exp(0.5 * vae.encoder[-1].weight.data).cpu().numpy()\n",
        "    }\n",
        "\n",
        "    return distribution_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "w4KAYT8XrV0I"
      },
      "outputs": [],
      "source": [
        "def send_distribution_info(distribution_info: Dict) -> None:\n",
        "    # Implement the logic to send the distribution information to the global server\n",
        "    # This can involve using a network protocol, a message queue, or any other communication mechanism\n",
        "    # to send the information\n",
        "\n",
        "    # Example implementation:\n",
        "    # Send the distribution information to the global server using a network protocol\n",
        "    # For example, you can use the `socket` module to send the information over a network\n",
        "    # or use a message queue like `RabbitMQ` to send the information\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1VV25UuEreCu"
      },
      "outputs": [],
      "source": [
        "# Define logic to generate augmented data using Ordinary Normal distribution\n",
        "def generate_augmented_data(vae: VAE, distribution_info: Dict) -> torch.Tensor:\n",
        "    # Generate augmented data using Ordinary Normal distribution\n",
        "    mean = distribution_info[\"mean\"]\n",
        "    std = distribution_info[\"std\"]\n",
        "    augmented_data = torch.randn(64, vae.z_dim) * std + mean\n",
        "    return augmented_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DCcpkdCHrmIR"
      },
      "outputs": [],
      "source": [
        "def federated_train(net: nn.Module, vae: VAE, trainloaders: Dict[str, DataLoader], trainloader: DataLoader, valloader: DataLoader, epochs: int) -> None:\n",
        "    for epoch in range(epochs):\n",
        "        for client_id, client_trainloader in trainloaders.items():\n",
        "            # Train VAE on client data\n",
        "            vae_train(vae, client_trainloader, epochs=10, beta=0.5)\n",
        "\n",
        "            # Share distribution information with global server\n",
        "            distribution_info = get_distribution_info(vae)\n",
        "            send_distribution_info(distribution_info)\n",
        "\n",
        "            # Receive distribution information from other clients\n",
        "            other_distribution_info = receive_distribution_info()\n",
        "\n",
        "            # Generate augmented data using received distribution information\n",
        "            augmented_data = generate_augmented_data(vae, other_distribution_info)\n",
        "\n",
        "            # Train classification model using local, augmented, and validation data\n",
        "            train(net, client_trainloader, valloader, epochs=10)\n",
        "\n",
        "            # Send model updates to global server\n",
        "            send_model_update(client_id, net.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "GFPgJKA4rwQ_"
      },
      "outputs": [],
      "source": [
        "# Define logic to receive distribution information from global server\n",
        "def receive_distribution_info() -> Dict:\n",
        "    # Receive distribution information logic\n",
        "    distribution_info = {\n",
        "        \"mean\": np.zeros(20),  # Adjust the size based on your latent space dimension\n",
        "        \"std\": np.ones(20)\n",
        "    }\n",
        "    return distribution_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "N7ficB30r2Qd"
      },
      "outputs": [],
      "source": [
        "def send_model_update(client_id: str, model_update: Dict) -> None:\n",
        "    # Implement the logic to send the model update to the global server\n",
        "    # This can involve using a network protocol, a message queue, or any other communication mechanism\n",
        "    # to send the model update\n",
        "\n",
        "    # Example implementation:\n",
        "    # Send the model update to the global server using a network protocol\n",
        "    # For example, you can use the `socket` module to send the information over a network\n",
        "    # or use a message queue like `RabbitMQ` to send the information\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLsoYA05GnCB"
      },
      "source": [
        "***-------For 250 Epochs B=0.5-------***\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuBS1wHyr4DW",
        "outputId": "8e625d14-bb89-4ac7-ed6a-cad7436d77ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-14-3419885715.py:6: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  augmented_data = torch.randn(64, vae.z_dim) * std + mean\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Training Loss: 2.305, Validation Accuracy: 10.22%\n",
            "Epoch [2/10], Training Loss: 2.304, Validation Accuracy: 10.22%\n",
            "Epoch [3/10], Training Loss: 2.303, Validation Accuracy: 10.22%\n",
            "Epoch [4/10], Training Loss: 2.302, Validation Accuracy: 10.25%\n",
            "Epoch [5/10], Training Loss: 2.301, Validation Accuracy: 11.11%\n",
            "Epoch [6/10], Training Loss: 2.300, Validation Accuracy: 12.28%\n",
            "Epoch [7/10], Training Loss: 2.300, Validation Accuracy: 13.01%\n",
            "Epoch [8/10], Training Loss: 2.299, Validation Accuracy: 13.34%\n",
            "Epoch [9/10], Training Loss: 2.297, Validation Accuracy: 13.38%\n",
            "Epoch [10/10], Training Loss: 2.296, Validation Accuracy: 13.78%\n",
            "Epoch [1/10], Training Loss: 2.295, Validation Accuracy: 13.40%\n",
            "Epoch [2/10], Training Loss: 2.292, Validation Accuracy: 13.21%\n",
            "Epoch [3/10], Training Loss: 2.289, Validation Accuracy: 13.03%\n",
            "Epoch [4/10], Training Loss: 2.284, Validation Accuracy: 13.43%\n",
            "Epoch [5/10], Training Loss: 2.277, Validation Accuracy: 14.44%\n",
            "Epoch [6/10], Training Loss: 2.267, Validation Accuracy: 18.44%\n",
            "Epoch [7/10], Training Loss: 2.252, Validation Accuracy: 20.53%\n",
            "Epoch [8/10], Training Loss: 2.227, Validation Accuracy: 21.15%\n",
            "Epoch [9/10], Training Loss: 2.190, Validation Accuracy: 21.79%\n",
            "Epoch [10/10], Training Loss: 2.147, Validation Accuracy: 22.38%\n",
            "Epoch [1/10], Training Loss: 2.126, Validation Accuracy: 24.46%\n",
            "Epoch [2/10], Training Loss: 2.097, Validation Accuracy: 25.56%\n",
            "Epoch [3/10], Training Loss: 2.072, Validation Accuracy: 26.78%\n",
            "Epoch [4/10], Training Loss: 2.044, Validation Accuracy: 27.32%\n",
            "Epoch [5/10], Training Loss: 2.017, Validation Accuracy: 28.17%\n",
            "Epoch [6/10], Training Loss: 1.994, Validation Accuracy: 28.99%\n",
            "Epoch [7/10], Training Loss: 1.977, Validation Accuracy: 29.32%\n",
            "Epoch [8/10], Training Loss: 1.961, Validation Accuracy: 29.20%\n",
            "Epoch [9/10], Training Loss: 1.948, Validation Accuracy: 30.33%\n",
            "Epoch [10/10], Training Loss: 1.936, Validation Accuracy: 30.88%\n",
            "Epoch [1/10], Training Loss: 1.942, Validation Accuracy: 30.08%\n",
            "Epoch [2/10], Training Loss: 1.932, Validation Accuracy: 31.70%\n",
            "Epoch [3/10], Training Loss: 1.916, Validation Accuracy: 31.08%\n",
            "Epoch [4/10], Training Loss: 1.906, Validation Accuracy: 31.93%\n",
            "Epoch [5/10], Training Loss: 1.890, Validation Accuracy: 32.25%\n",
            "Epoch [6/10], Training Loss: 1.874, Validation Accuracy: 33.14%\n",
            "Epoch [7/10], Training Loss: 1.859, Validation Accuracy: 33.57%\n",
            "Epoch [8/10], Training Loss: 1.846, Validation Accuracy: 34.14%\n",
            "Epoch [9/10], Training Loss: 1.833, Validation Accuracy: 33.95%\n",
            "Epoch [10/10], Training Loss: 1.810, Validation Accuracy: 34.96%\n",
            "Epoch [1/10], Training Loss: 1.796, Validation Accuracy: 35.24%\n",
            "Epoch [2/10], Training Loss: 1.778, Validation Accuracy: 35.84%\n",
            "Epoch [3/10], Training Loss: 1.757, Validation Accuracy: 36.86%\n",
            "Epoch [4/10], Training Loss: 1.740, Validation Accuracy: 36.83%\n",
            "Epoch [5/10], Training Loss: 1.719, Validation Accuracy: 36.67%\n",
            "Epoch [6/10], Training Loss: 1.706, Validation Accuracy: 38.49%\n",
            "Epoch [7/10], Training Loss: 1.692, Validation Accuracy: 38.27%\n",
            "Epoch [8/10], Training Loss: 1.674, Validation Accuracy: 38.49%\n",
            "Epoch [9/10], Training Loss: 1.659, Validation Accuracy: 39.02%\n",
            "Epoch [10/10], Training Loss: 1.653, Validation Accuracy: 39.51%\n",
            "Epoch [1/10], Training Loss: 1.648, Validation Accuracy: 40.37%\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Define global server procedure\n",
        "def global_server() -> None:\n",
        "    net = Net()\n",
        "    x_dim = 3 * 32 * 32  # CIFAR-10 input size\n",
        "    h_dim = 400\n",
        "    z_dim = 20\n",
        "    vae = VAE(x_dim, h_dim, z_dim)  # Initialize VAE object with required arguments\n",
        "\n",
        "    # Initialize clients\n",
        "    num_clients = 5  # Define the number of clients\n",
        "    clients = initialize_clients(train_set, transform, batch_size=128, num_clients=num_clients)\n",
        "\n",
        "    # Train model using FedDIS\n",
        "    federated_train(net, vae, clients, trainloader, valloader, epochs=5)\n",
        "\n",
        "    # Evaluate final model\n",
        "    test_accuracy = evaluate(net, testloader)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    global_server()\n"
      ]
    }
  ]
}