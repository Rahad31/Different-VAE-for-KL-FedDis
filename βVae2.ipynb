{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVuZISpQ2Bw4O7gPBafU0j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahad31/Different-VAE-for-KL-FedDis/blob/main/%CE%B2Vae2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "McbpNS0ya3aP"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "34hGoqpxKY7G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yELruI1IpCqt",
        "outputId": "fabc3f36-5776-4321-9d4f-44768897cc22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 7.76 s, sys: 920 ms, total: 8.68 s\n",
            "Wall time: 14.4 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch import nn\n",
        "from typing import Dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WoJ24tiipdHG"
      },
      "outputs": [],
      "source": [
        "# Define VAE model\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, x_dim, h_dim, z_dim):\n",
        "        super(VAE, self).__init__()\n",
        "        self.x_dim = x_dim\n",
        "        self.h_dim = h_dim\n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        # Encoder\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 4, stride=2, padding=1),  # 16x16\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 4, stride=2, padding=1),  # 8x8\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 4, stride=2, padding=1),  # 4x4\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(2048, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2*z_dim)\n",
        "        )\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(z_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Unflatten(1, (128, 4, 4)),\n",
        "            nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1),  # 8x8\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),  # 16x16\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, 4, stride=2, padding=1),  # 32x32\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        h = self.encoder(x)\n",
        "        mu, logvar = h[:, :self.z_dim], h[:, self.z_dim:]\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(z)\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uEU_HGlkpjMy"
      },
      "outputs": [],
      "source": [
        "def vae_train(vae: VAE, trainloader: DataLoader, epochs: int, beta: float = 0.5) -> None:\n",
        "    optimizer = torch.optim.Adam(vae.parameters(), lr=1e-3)\n",
        "    for epoch in range(epochs):\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, _ = data\n",
        "            optimizer.zero_grad()\n",
        "            recon_x, mu, logvar = vae(inputs)\n",
        "            loss = vae_loss(recon_x, inputs, mu, logvar, beta=beta)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "77xTShYPp7Tp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define classification model\n",
        "class Net(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
        "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = nn.functional.relu(self.fc1(x))\n",
        "        x = nn.functional.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "LIMyvsHZqA0S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b85ceea3-1a0b-46b6-92f6-64febec57502"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:10<00:00, 15.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Load CIFAR10 dataset\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "full_dataset = CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n",
        "test_set = CIFAR10(root=\"./data\", train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HBc6iayKqMoT"
      },
      "outputs": [],
      "source": [
        "# Split dataset into training and validation sets\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = len(full_dataset) - train_size\n",
        "train_set, val_set = torch.utils.data.random_split(full_dataset, [train_size, val_size])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "D1qRZ4OgqQkh"
      },
      "outputs": [],
      "source": [
        "# Create training and validation loaders\n",
        "trainloader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(val_set, batch_size=128, shuffle=False, num_workers=2)\n",
        "testloader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-I3RRdp7qwie"
      },
      "outputs": [],
      "source": [
        "def vae_loss(recon_x, x, mu, logvar, beta=0.5):\n",
        "    BCE = nn.functional.mse_loss(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + beta * KLD\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vv4Dbvl2q2za"
      },
      "outputs": [],
      "source": [
        "# Define training procedure for classification model\n",
        "def train(net: nn.Module, trainloader: DataLoader, valloader: DataLoader, epochs: int) -> None:\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training loop\n",
        "        net.train()\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Validation loop\n",
        "        net.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in valloader:\n",
        "                images, labels = data\n",
        "                outputs = net(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        val_acc = 100 * correct / total\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save(net.state_dict(), 'best_model.pth')\n",
        "\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Training Loss: {running_loss / (i+1):.3f}, Validation Accuracy: {val_acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IoIsl09zq76r"
      },
      "outputs": [],
      "source": [
        "# Define evaluation procedure\n",
        "def evaluate(net: nn.Module, testloader: DataLoader) -> float:\n",
        "    net.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Z4_GLIx3rL3l"
      },
      "outputs": [],
      "source": [
        "def initialize_clients(trainset, transform, batch_size, num_clients):\n",
        "    clients = {}\n",
        "    for i in range(num_clients):\n",
        "        client_trainset = torch.utils.data.Subset(trainset, range(i * len(trainset) // num_clients, (i + 1) * len(trainset) // num_clients))\n",
        "        client_trainloader = torch.utils.data.DataLoader(client_trainset, batch_size=batch_size, shuffle=True)\n",
        "        clients[f\"client_{i}\"] = client_trainloader\n",
        "    return clients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "iYhcZLZDrR6I"
      },
      "outputs": [],
      "source": [
        "def get_distribution_info(vae: VAE) -> Dict:\n",
        "    # Implement the logic to extract distribution information from the VAE\n",
        "    # This can involve computing statistics, parameters, or any other relevant information\n",
        "    # that can be used to generate augmented data\n",
        "\n",
        "    # Example implementation:\n",
        "    distribution_info = {\n",
        "        \"mean\": vae.encoder[-1].bias.data.cpu().numpy(),\n",
        "        \"std\": torch.exp(0.5 * vae.encoder[-1].weight.data).cpu().numpy()\n",
        "    }\n",
        "\n",
        "    return distribution_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "w4KAYT8XrV0I"
      },
      "outputs": [],
      "source": [
        "def send_distribution_info(distribution_info: Dict) -> None:\n",
        "    # Implement the logic to send the distribution information to the global server\n",
        "    # This can involve using a network protocol, a message queue, or any other communication mechanism\n",
        "    # to send the information\n",
        "\n",
        "    # Example implementation:\n",
        "    # Send the distribution information to the global server using a network protocol\n",
        "    # For example, you can use the `socket` module to send the information over a network\n",
        "    # or use a message queue like `RabbitMQ` to send the information\n",
        "    pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1VV25UuEreCu"
      },
      "outputs": [],
      "source": [
        "# Define logic to generate augmented data using Ordinary Normal distribution\n",
        "def generate_augmented_data(vae: VAE, distribution_info: Dict) -> torch.Tensor:\n",
        "    # Generate augmented data using Ordinary Normal distribution\n",
        "    mean = distribution_info[\"mean\"]\n",
        "    std = distribution_info[\"std\"]\n",
        "    augmented_data = torch.randn(64, vae.z_dim) * std + mean\n",
        "    return augmented_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DCcpkdCHrmIR"
      },
      "outputs": [],
      "source": [
        "def federated_train(net: nn.Module, vae: VAE, trainloaders: Dict[str, DataLoader], trainloader: DataLoader, valloader: DataLoader, epochs: int) -> None:\n",
        "    for epoch in range(epochs):\n",
        "        for client_id, client_trainloader in trainloaders.items():\n",
        "            # Train VAE on client data\n",
        "            vae_train(vae, client_trainloader, epochs=10, beta=0.5)\n",
        "\n",
        "            # Share distribution information with global server\n",
        "            distribution_info = get_distribution_info(vae)\n",
        "            send_distribution_info(distribution_info)\n",
        "\n",
        "            # Receive distribution information from other clients\n",
        "            other_distribution_info = receive_distribution_info()\n",
        "\n",
        "            # Generate augmented data using received distribution information\n",
        "            augmented_data = generate_augmented_data(vae, other_distribution_info)\n",
        "\n",
        "            # Train classification model using local, augmented, and validation data\n",
        "            train(net, client_trainloader, valloader, epochs=10)\n",
        "\n",
        "            # Send model updates to global server\n",
        "            send_model_update(client_id, net.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GFPgJKA4rwQ_"
      },
      "outputs": [],
      "source": [
        "# Define logic to receive distribution information from global server\n",
        "def receive_distribution_info() -> Dict:\n",
        "    # Receive distribution information logic\n",
        "    distribution_info = {\n",
        "        \"mean\": np.zeros(20),  # Adjust the size based on your latent space dimension\n",
        "        \"std\": np.ones(20)\n",
        "    }\n",
        "    return distribution_info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "N7ficB30r2Qd"
      },
      "outputs": [],
      "source": [
        "def send_model_update(client_id: str, model_update: Dict) -> None:\n",
        "    # Implement the logic to send the model update to the global server\n",
        "    # This can involve using a network protocol, a message queue, or any other communication mechanism\n",
        "    # to send the model update\n",
        "\n",
        "    # Example implementation:\n",
        "    # Send the model update to the global server using a network protocol\n",
        "    # For example, you can use the `socket` module to send the information over a network\n",
        "    # or use a message queue like `RabbitMQ` to send the information\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLsoYA05GnCB"
      },
      "source": [
        "***-------For 250 Epochs B=0.5-------***\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuBS1wHyr4DW",
        "outputId": "8e625d14-bb89-4ac7-ed6a-cad7436d77ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-14-3419885715.py:6: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  augmented_data = torch.randn(64, vae.z_dim) * std + mean\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Training Loss: 2.305, Validation Accuracy: 10.22%\n",
            "Epoch [2/10], Training Loss: 2.304, Validation Accuracy: 10.22%\n",
            "Epoch [3/10], Training Loss: 2.303, Validation Accuracy: 10.22%\n",
            "Epoch [4/10], Training Loss: 2.302, Validation Accuracy: 10.25%\n",
            "Epoch [5/10], Training Loss: 2.301, Validation Accuracy: 11.11%\n",
            "Epoch [6/10], Training Loss: 2.300, Validation Accuracy: 12.28%\n",
            "Epoch [7/10], Training Loss: 2.300, Validation Accuracy: 13.01%\n",
            "Epoch [8/10], Training Loss: 2.299, Validation Accuracy: 13.34%\n",
            "Epoch [9/10], Training Loss: 2.297, Validation Accuracy: 13.38%\n",
            "Epoch [10/10], Training Loss: 2.296, Validation Accuracy: 13.78%\n",
            "Epoch [1/10], Training Loss: 2.295, Validation Accuracy: 13.40%\n",
            "Epoch [2/10], Training Loss: 2.292, Validation Accuracy: 13.21%\n",
            "Epoch [3/10], Training Loss: 2.289, Validation Accuracy: 13.03%\n",
            "Epoch [4/10], Training Loss: 2.284, Validation Accuracy: 13.43%\n",
            "Epoch [5/10], Training Loss: 2.277, Validation Accuracy: 14.44%\n",
            "Epoch [6/10], Training Loss: 2.267, Validation Accuracy: 18.44%\n",
            "Epoch [7/10], Training Loss: 2.252, Validation Accuracy: 20.53%\n",
            "Epoch [8/10], Training Loss: 2.227, Validation Accuracy: 21.15%\n",
            "Epoch [9/10], Training Loss: 2.190, Validation Accuracy: 21.79%\n",
            "Epoch [10/10], Training Loss: 2.147, Validation Accuracy: 22.38%\n",
            "Epoch [1/10], Training Loss: 2.126, Validation Accuracy: 24.46%\n",
            "Epoch [2/10], Training Loss: 2.097, Validation Accuracy: 25.56%\n",
            "Epoch [3/10], Training Loss: 2.072, Validation Accuracy: 26.78%\n",
            "Epoch [4/10], Training Loss: 2.044, Validation Accuracy: 27.32%\n",
            "Epoch [5/10], Training Loss: 2.017, Validation Accuracy: 28.17%\n",
            "Epoch [6/10], Training Loss: 1.994, Validation Accuracy: 28.99%\n",
            "Epoch [7/10], Training Loss: 1.977, Validation Accuracy: 29.32%\n",
            "Epoch [8/10], Training Loss: 1.961, Validation Accuracy: 29.20%\n",
            "Epoch [9/10], Training Loss: 1.948, Validation Accuracy: 30.33%\n",
            "Epoch [10/10], Training Loss: 1.936, Validation Accuracy: 30.88%\n",
            "Epoch [1/10], Training Loss: 1.942, Validation Accuracy: 30.08%\n",
            "Epoch [2/10], Training Loss: 1.932, Validation Accuracy: 31.70%\n",
            "Epoch [3/10], Training Loss: 1.916, Validation Accuracy: 31.08%\n",
            "Epoch [4/10], Training Loss: 1.906, Validation Accuracy: 31.93%\n",
            "Epoch [5/10], Training Loss: 1.890, Validation Accuracy: 32.25%\n",
            "Epoch [6/10], Training Loss: 1.874, Validation Accuracy: 33.14%\n",
            "Epoch [7/10], Training Loss: 1.859, Validation Accuracy: 33.57%\n",
            "Epoch [8/10], Training Loss: 1.846, Validation Accuracy: 34.14%\n",
            "Epoch [9/10], Training Loss: 1.833, Validation Accuracy: 33.95%\n",
            "Epoch [10/10], Training Loss: 1.810, Validation Accuracy: 34.96%\n",
            "Epoch [1/10], Training Loss: 1.796, Validation Accuracy: 35.24%\n",
            "Epoch [2/10], Training Loss: 1.778, Validation Accuracy: 35.84%\n",
            "Epoch [3/10], Training Loss: 1.757, Validation Accuracy: 36.86%\n",
            "Epoch [4/10], Training Loss: 1.740, Validation Accuracy: 36.83%\n",
            "Epoch [5/10], Training Loss: 1.719, Validation Accuracy: 36.67%\n",
            "Epoch [6/10], Training Loss: 1.706, Validation Accuracy: 38.49%\n",
            "Epoch [7/10], Training Loss: 1.692, Validation Accuracy: 38.27%\n",
            "Epoch [8/10], Training Loss: 1.674, Validation Accuracy: 38.49%\n",
            "Epoch [9/10], Training Loss: 1.659, Validation Accuracy: 39.02%\n",
            "Epoch [10/10], Training Loss: 1.653, Validation Accuracy: 39.51%\n",
            "Epoch [1/10], Training Loss: 1.648, Validation Accuracy: 40.37%\n",
            "Epoch [2/10], Training Loss: 1.640, Validation Accuracy: 39.73%\n",
            "Epoch [3/10], Training Loss: 1.623, Validation Accuracy: 41.22%\n",
            "Epoch [4/10], Training Loss: 1.607, Validation Accuracy: 41.71%\n",
            "Epoch [5/10], Training Loss: 1.593, Validation Accuracy: 40.29%\n",
            "Epoch [6/10], Training Loss: 1.596, Validation Accuracy: 42.13%\n",
            "Epoch [7/10], Training Loss: 1.578, Validation Accuracy: 42.35%\n",
            "Epoch [8/10], Training Loss: 1.558, Validation Accuracy: 43.30%\n",
            "Epoch [9/10], Training Loss: 1.554, Validation Accuracy: 42.47%\n",
            "Epoch [10/10], Training Loss: 1.542, Validation Accuracy: 43.45%\n",
            "Epoch [1/10], Training Loss: 1.579, Validation Accuracy: 43.04%\n",
            "Epoch [2/10], Training Loss: 1.567, Validation Accuracy: 44.43%\n",
            "Epoch [3/10], Training Loss: 1.551, Validation Accuracy: 44.52%\n",
            "Epoch [4/10], Training Loss: 1.546, Validation Accuracy: 44.40%\n",
            "Epoch [5/10], Training Loss: 1.537, Validation Accuracy: 44.35%\n",
            "Epoch [6/10], Training Loss: 1.529, Validation Accuracy: 44.03%\n",
            "Epoch [7/10], Training Loss: 1.513, Validation Accuracy: 44.99%\n",
            "Epoch [8/10], Training Loss: 1.502, Validation Accuracy: 44.66%\n",
            "Epoch [9/10], Training Loss: 1.500, Validation Accuracy: 45.12%\n",
            "Epoch [10/10], Training Loss: 1.486, Validation Accuracy: 45.62%\n",
            "Epoch [1/10], Training Loss: 1.506, Validation Accuracy: 45.21%\n",
            "Epoch [2/10], Training Loss: 1.499, Validation Accuracy: 45.89%\n",
            "Epoch [3/10], Training Loss: 1.482, Validation Accuracy: 45.87%\n",
            "Epoch [4/10], Training Loss: 1.470, Validation Accuracy: 46.16%\n",
            "Epoch [5/10], Training Loss: 1.460, Validation Accuracy: 46.85%\n",
            "Epoch [6/10], Training Loss: 1.445, Validation Accuracy: 46.98%\n",
            "Epoch [7/10], Training Loss: 1.436, Validation Accuracy: 46.65%\n",
            "Epoch [8/10], Training Loss: 1.428, Validation Accuracy: 46.74%\n",
            "Epoch [9/10], Training Loss: 1.421, Validation Accuracy: 45.60%\n",
            "Epoch [10/10], Training Loss: 1.419, Validation Accuracy: 46.88%\n",
            "Epoch [1/10], Training Loss: 1.482, Validation Accuracy: 47.19%\n",
            "Epoch [2/10], Training Loss: 1.470, Validation Accuracy: 47.65%\n",
            "Epoch [3/10], Training Loss: 1.452, Validation Accuracy: 47.00%\n",
            "Epoch [4/10], Training Loss: 1.451, Validation Accuracy: 48.12%\n",
            "Epoch [5/10], Training Loss: 1.433, Validation Accuracy: 47.63%\n",
            "Epoch [6/10], Training Loss: 1.423, Validation Accuracy: 48.08%\n",
            "Epoch [7/10], Training Loss: 1.418, Validation Accuracy: 48.34%\n",
            "Epoch [8/10], Training Loss: 1.405, Validation Accuracy: 47.68%\n",
            "Epoch [9/10], Training Loss: 1.396, Validation Accuracy: 48.14%\n",
            "Epoch [10/10], Training Loss: 1.398, Validation Accuracy: 47.84%\n",
            "Epoch [1/10], Training Loss: 1.419, Validation Accuracy: 48.93%\n",
            "Epoch [2/10], Training Loss: 1.396, Validation Accuracy: 49.78%\n",
            "Epoch [3/10], Training Loss: 1.383, Validation Accuracy: 49.39%\n",
            "Epoch [4/10], Training Loss: 1.370, Validation Accuracy: 49.29%\n",
            "Epoch [5/10], Training Loss: 1.356, Validation Accuracy: 49.36%\n",
            "Epoch [6/10], Training Loss: 1.350, Validation Accuracy: 49.58%\n",
            "Epoch [7/10], Training Loss: 1.346, Validation Accuracy: 50.04%\n",
            "Epoch [8/10], Training Loss: 1.337, Validation Accuracy: 49.93%\n",
            "Epoch [9/10], Training Loss: 1.320, Validation Accuracy: 49.55%\n",
            "Epoch [10/10], Training Loss: 1.317, Validation Accuracy: 50.39%\n",
            "Epoch [1/10], Training Loss: 1.377, Validation Accuracy: 50.83%\n",
            "Epoch [2/10], Training Loss: 1.356, Validation Accuracy: 49.44%\n",
            "Epoch [3/10], Training Loss: 1.340, Validation Accuracy: 50.79%\n",
            "Epoch [4/10], Training Loss: 1.332, Validation Accuracy: 49.75%\n",
            "Epoch [5/10], Training Loss: 1.322, Validation Accuracy: 50.87%\n",
            "Epoch [6/10], Training Loss: 1.309, Validation Accuracy: 51.24%\n",
            "Epoch [7/10], Training Loss: 1.300, Validation Accuracy: 51.41%\n",
            "Epoch [8/10], Training Loss: 1.286, Validation Accuracy: 51.02%\n",
            "Epoch [9/10], Training Loss: 1.281, Validation Accuracy: 52.00%\n",
            "Epoch [10/10], Training Loss: 1.274, Validation Accuracy: 51.15%\n",
            "Epoch [1/10], Training Loss: 1.360, Validation Accuracy: 51.65%\n",
            "Epoch [2/10], Training Loss: 1.330, Validation Accuracy: 52.41%\n",
            "Epoch [3/10], Training Loss: 1.312, Validation Accuracy: 51.78%\n",
            "Epoch [4/10], Training Loss: 1.305, Validation Accuracy: 51.59%\n",
            "Epoch [5/10], Training Loss: 1.299, Validation Accuracy: 52.17%\n",
            "Epoch [6/10], Training Loss: 1.285, Validation Accuracy: 51.57%\n",
            "Epoch [7/10], Training Loss: 1.270, Validation Accuracy: 52.49%\n",
            "Epoch [8/10], Training Loss: 1.262, Validation Accuracy: 52.88%\n",
            "Epoch [9/10], Training Loss: 1.254, Validation Accuracy: 53.01%\n",
            "Epoch [10/10], Training Loss: 1.243, Validation Accuracy: 52.71%\n",
            "Epoch [1/10], Training Loss: 1.303, Validation Accuracy: 53.57%\n",
            "Epoch [2/10], Training Loss: 1.284, Validation Accuracy: 53.05%\n",
            "Epoch [3/10], Training Loss: 1.270, Validation Accuracy: 53.49%\n",
            "Epoch [4/10], Training Loss: 1.249, Validation Accuracy: 53.53%\n",
            "Epoch [5/10], Training Loss: 1.246, Validation Accuracy: 52.30%\n",
            "Epoch [6/10], Training Loss: 1.232, Validation Accuracy: 53.22%\n",
            "Epoch [7/10], Training Loss: 1.218, Validation Accuracy: 53.16%\n",
            "Epoch [8/10], Training Loss: 1.209, Validation Accuracy: 53.88%\n",
            "Epoch [9/10], Training Loss: 1.202, Validation Accuracy: 53.86%\n",
            "Epoch [10/10], Training Loss: 1.184, Validation Accuracy: 53.82%\n",
            "Epoch [1/10], Training Loss: 1.298, Validation Accuracy: 54.23%\n",
            "Epoch [2/10], Training Loss: 1.273, Validation Accuracy: 53.68%\n",
            "Epoch [3/10], Training Loss: 1.257, Validation Accuracy: 52.74%\n",
            "Epoch [4/10], Training Loss: 1.239, Validation Accuracy: 54.84%\n",
            "Epoch [5/10], Training Loss: 1.222, Validation Accuracy: 54.00%\n",
            "Epoch [6/10], Training Loss: 1.220, Validation Accuracy: 54.54%\n",
            "Epoch [7/10], Training Loss: 1.198, Validation Accuracy: 54.99%\n",
            "Epoch [8/10], Training Loss: 1.191, Validation Accuracy: 54.22%\n",
            "Epoch [9/10], Training Loss: 1.182, Validation Accuracy: 54.65%\n",
            "Epoch [10/10], Training Loss: 1.177, Validation Accuracy: 54.72%\n",
            "Epoch [1/10], Training Loss: 1.241, Validation Accuracy: 55.08%\n",
            "Epoch [2/10], Training Loss: 1.222, Validation Accuracy: 55.43%\n",
            "Epoch [3/10], Training Loss: 1.212, Validation Accuracy: 53.79%\n",
            "Epoch [4/10], Training Loss: 1.194, Validation Accuracy: 55.41%\n",
            "Epoch [5/10], Training Loss: 1.184, Validation Accuracy: 55.21%\n",
            "Epoch [6/10], Training Loss: 1.164, Validation Accuracy: 55.08%\n",
            "Epoch [7/10], Training Loss: 1.154, Validation Accuracy: 55.86%\n",
            "Epoch [8/10], Training Loss: 1.147, Validation Accuracy: 55.35%\n",
            "Epoch [9/10], Training Loss: 1.132, Validation Accuracy: 55.44%\n",
            "Epoch [10/10], Training Loss: 1.128, Validation Accuracy: 55.64%\n",
            "Epoch [1/10], Training Loss: 1.225, Validation Accuracy: 55.06%\n",
            "Epoch [2/10], Training Loss: 1.202, Validation Accuracy: 56.13%\n",
            "Epoch [3/10], Training Loss: 1.172, Validation Accuracy: 55.79%\n",
            "Epoch [4/10], Training Loss: 1.166, Validation Accuracy: 55.87%\n",
            "Epoch [5/10], Training Loss: 1.151, Validation Accuracy: 55.21%\n",
            "Epoch [6/10], Training Loss: 1.143, Validation Accuracy: 55.30%\n",
            "Epoch [7/10], Training Loss: 1.131, Validation Accuracy: 56.14%\n",
            "Epoch [8/10], Training Loss: 1.116, Validation Accuracy: 55.77%\n",
            "Epoch [9/10], Training Loss: 1.107, Validation Accuracy: 55.86%\n",
            "Epoch [10/10], Training Loss: 1.099, Validation Accuracy: 56.25%\n",
            "Epoch [1/10], Training Loss: 1.200, Validation Accuracy: 55.67%\n",
            "Epoch [2/10], Training Loss: 1.178, Validation Accuracy: 57.13%\n",
            "Epoch [3/10], Training Loss: 1.155, Validation Accuracy: 57.01%\n",
            "Epoch [4/10], Training Loss: 1.132, Validation Accuracy: 57.16%\n",
            "Epoch [5/10], Training Loss: 1.130, Validation Accuracy: 57.05%\n",
            "Epoch [6/10], Training Loss: 1.118, Validation Accuracy: 56.34%\n",
            "Epoch [7/10], Training Loss: 1.105, Validation Accuracy: 57.09%\n",
            "Epoch [8/10], Training Loss: 1.095, Validation Accuracy: 57.70%\n",
            "Epoch [9/10], Training Loss: 1.079, Validation Accuracy: 57.09%\n",
            "Epoch [10/10], Training Loss: 1.075, Validation Accuracy: 56.75%\n",
            "Epoch [1/10], Training Loss: 1.169, Validation Accuracy: 57.08%\n",
            "Epoch [2/10], Training Loss: 1.143, Validation Accuracy: 57.72%\n",
            "Epoch [3/10], Training Loss: 1.111, Validation Accuracy: 57.22%\n",
            "Epoch [4/10], Training Loss: 1.099, Validation Accuracy: 55.95%\n",
            "Epoch [5/10], Training Loss: 1.090, Validation Accuracy: 58.09%\n",
            "Epoch [6/10], Training Loss: 1.071, Validation Accuracy: 57.33%\n",
            "Epoch [7/10], Training Loss: 1.057, Validation Accuracy: 56.47%\n",
            "Epoch [8/10], Training Loss: 1.060, Validation Accuracy: 57.46%\n",
            "Epoch [9/10], Training Loss: 1.036, Validation Accuracy: 57.88%\n",
            "Epoch [10/10], Training Loss: 1.020, Validation Accuracy: 58.17%\n",
            "Epoch [1/10], Training Loss: 1.167, Validation Accuracy: 57.38%\n",
            "Epoch [2/10], Training Loss: 1.136, Validation Accuracy: 57.32%\n",
            "Epoch [3/10], Training Loss: 1.104, Validation Accuracy: 58.70%\n",
            "Epoch [4/10], Training Loss: 1.091, Validation Accuracy: 57.88%\n",
            "Epoch [5/10], Training Loss: 1.070, Validation Accuracy: 58.42%\n",
            "Epoch [6/10], Training Loss: 1.059, Validation Accuracy: 58.52%\n",
            "Epoch [7/10], Training Loss: 1.050, Validation Accuracy: 57.91%\n",
            "Epoch [8/10], Training Loss: 1.038, Validation Accuracy: 58.22%\n",
            "Epoch [9/10], Training Loss: 1.030, Validation Accuracy: 56.91%\n",
            "Epoch [10/10], Training Loss: 1.024, Validation Accuracy: 58.15%\n",
            "Epoch [1/10], Training Loss: 1.130, Validation Accuracy: 58.89%\n",
            "Epoch [2/10], Training Loss: 1.104, Validation Accuracy: 58.28%\n",
            "Epoch [3/10], Training Loss: 1.081, Validation Accuracy: 58.30%\n",
            "Epoch [4/10], Training Loss: 1.066, Validation Accuracy: 58.46%\n",
            "Epoch [5/10], Training Loss: 1.041, Validation Accuracy: 58.81%\n",
            "Epoch [6/10], Training Loss: 1.031, Validation Accuracy: 58.16%\n",
            "Epoch [7/10], Training Loss: 1.014, Validation Accuracy: 58.25%\n",
            "Epoch [8/10], Training Loss: 1.011, Validation Accuracy: 57.62%\n",
            "Epoch [9/10], Training Loss: 0.992, Validation Accuracy: 59.07%\n",
            "Epoch [10/10], Training Loss: 0.983, Validation Accuracy: 58.56%\n",
            "Epoch [1/10], Training Loss: 1.110, Validation Accuracy: 58.06%\n",
            "Epoch [2/10], Training Loss: 1.077, Validation Accuracy: 58.00%\n",
            "Epoch [3/10], Training Loss: 1.057, Validation Accuracy: 59.42%\n",
            "Epoch [4/10], Training Loss: 1.041, Validation Accuracy: 58.35%\n",
            "Epoch [5/10], Training Loss: 1.032, Validation Accuracy: 59.74%\n",
            "Epoch [6/10], Training Loss: 1.004, Validation Accuracy: 58.55%\n",
            "Epoch [7/10], Training Loss: 0.989, Validation Accuracy: 59.60%\n",
            "Epoch [8/10], Training Loss: 0.976, Validation Accuracy: 59.58%\n",
            "Epoch [9/10], Training Loss: 0.966, Validation Accuracy: 58.70%\n",
            "Epoch [10/10], Training Loss: 0.964, Validation Accuracy: 58.89%\n",
            "Epoch [1/10], Training Loss: 1.101, Validation Accuracy: 58.59%\n",
            "Epoch [2/10], Training Loss: 1.059, Validation Accuracy: 59.86%\n",
            "Epoch [3/10], Training Loss: 1.028, Validation Accuracy: 59.39%\n",
            "Epoch [4/10], Training Loss: 1.014, Validation Accuracy: 59.52%\n",
            "Epoch [5/10], Training Loss: 0.991, Validation Accuracy: 60.45%\n",
            "Epoch [6/10], Training Loss: 0.982, Validation Accuracy: 59.93%\n",
            "Epoch [7/10], Training Loss: 0.967, Validation Accuracy: 59.79%\n",
            "Epoch [8/10], Training Loss: 0.948, Validation Accuracy: 60.22%\n",
            "Epoch [9/10], Training Loss: 0.940, Validation Accuracy: 60.33%\n",
            "Epoch [10/10], Training Loss: 0.927, Validation Accuracy: 59.30%\n",
            "Epoch [1/10], Training Loss: 1.075, Validation Accuracy: 59.99%\n",
            "Epoch [2/10], Training Loss: 1.025, Validation Accuracy: 60.34%\n",
            "Epoch [3/10], Training Loss: 1.001, Validation Accuracy: 59.59%\n",
            "Epoch [4/10], Training Loss: 0.983, Validation Accuracy: 60.69%\n",
            "Epoch [5/10], Training Loss: 0.960, Validation Accuracy: 59.48%\n",
            "Epoch [6/10], Training Loss: 0.945, Validation Accuracy: 60.11%\n",
            "Epoch [7/10], Training Loss: 0.930, Validation Accuracy: 59.96%\n",
            "Epoch [8/10], Training Loss: 0.919, Validation Accuracy: 59.67%\n",
            "Epoch [9/10], Training Loss: 0.904, Validation Accuracy: 60.59%\n",
            "Epoch [10/10], Training Loss: 0.897, Validation Accuracy: 60.27%\n",
            "Epoch [1/10], Training Loss: 1.067, Validation Accuracy: 60.67%\n",
            "Epoch [2/10], Training Loss: 1.021, Validation Accuracy: 60.62%\n",
            "Epoch [3/10], Training Loss: 0.990, Validation Accuracy: 61.12%\n",
            "Epoch [4/10], Training Loss: 0.968, Validation Accuracy: 60.66%\n",
            "Epoch [5/10], Training Loss: 0.953, Validation Accuracy: 60.76%\n",
            "Epoch [6/10], Training Loss: 0.940, Validation Accuracy: 60.99%\n",
            "Epoch [7/10], Training Loss: 0.921, Validation Accuracy: 60.08%\n",
            "Epoch [8/10], Training Loss: 0.905, Validation Accuracy: 59.90%\n",
            "Epoch [9/10], Training Loss: 0.891, Validation Accuracy: 59.75%\n",
            "Epoch [10/10], Training Loss: 0.879, Validation Accuracy: 59.96%\n",
            "Epoch [1/10], Training Loss: 1.044, Validation Accuracy: 59.63%\n",
            "Epoch [2/10], Training Loss: 1.005, Validation Accuracy: 60.76%\n",
            "Epoch [3/10], Training Loss: 0.972, Validation Accuracy: 60.05%\n",
            "Epoch [4/10], Training Loss: 0.949, Validation Accuracy: 60.79%\n",
            "Epoch [5/10], Training Loss: 0.931, Validation Accuracy: 61.17%\n",
            "Epoch [6/10], Training Loss: 0.911, Validation Accuracy: 60.71%\n",
            "Epoch [7/10], Training Loss: 0.902, Validation Accuracy: 60.75%\n",
            "Epoch [8/10], Training Loss: 0.881, Validation Accuracy: 61.05%\n",
            "Epoch [9/10], Training Loss: 0.867, Validation Accuracy: 60.54%\n",
            "Epoch [10/10], Training Loss: 0.856, Validation Accuracy: 60.64%\n",
            "Test Accuracy: 60.64%\n",
            "CPU times: user 1h 3min 31s, sys: 28.7 s, total: 1h 4min\n",
            "Wall time: 1h 8min 14s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "# Define global server procedure\n",
        "def global_server() -> None:\n",
        "    net = Net()\n",
        "    x_dim = 3 * 32 * 32  # CIFAR-10 input size\n",
        "    h_dim = 400\n",
        "    z_dim = 20\n",
        "    vae = VAE(x_dim, h_dim, z_dim)  # Initialize VAE object with required arguments\n",
        "\n",
        "    # Initialize clients\n",
        "    num_clients = 5  # Define the number of clients\n",
        "    clients = initialize_clients(train_set, transform, batch_size=128, num_clients=num_clients)\n",
        "\n",
        "    # Train model using FedDIS\n",
        "    federated_train(net, vae, clients, trainloader, valloader, epochs=5)\n",
        "\n",
        "    # Evaluate final model\n",
        "    test_accuracy = evaluate(net, testloader)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    global_server()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Define global server procedure\n",
        "def global_server() -> None:\n",
        "    net = Net()\n",
        "    x_dim = 3 * 32 * 32  # CIFAR-10 input size\n",
        "    h_dim = 400\n",
        "    z_dim = 20\n",
        "    vae = VAE(x_dim, h_dim, z_dim)  # Initialize VAE object with required arguments\n",
        "\n",
        "    # Initialize clients\n",
        "    num_clients = 5  # Define the number of clients\n",
        "    clients = initialize_clients(train_set, transform, batch_size=128, num_clients=num_clients)\n",
        "\n",
        "    # Train model using FedDIS\n",
        "    federated_train(net, vae, clients, trainloader, valloader, epochs=10)\n",
        "\n",
        "    # Evaluate final model\n",
        "    test_accuracy = evaluate(net, testloader)\n",
        "    print(f\"Test Accuracy: {test_accuracy:.2f}%\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    global_server()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4yIqB32uN-m",
        "outputId": "21688612-fc46-44d7-a000-68471dfe2de2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-15-3419885715.py:6: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
            "  augmented_data = torch.randn(64, vae.z_dim) * std + mean\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Training Loss: 2.305, Validation Accuracy: 10.75%\n",
            "Epoch [2/10], Training Loss: 2.304, Validation Accuracy: 10.89%\n",
            "Epoch [3/10], Training Loss: 2.303, Validation Accuracy: 10.98%\n",
            "Epoch [4/10], Training Loss: 2.302, Validation Accuracy: 10.96%\n",
            "Epoch [5/10], Training Loss: 2.300, Validation Accuracy: 11.33%\n",
            "Epoch [6/10], Training Loss: 2.298, Validation Accuracy: 12.83%\n",
            "Epoch [7/10], Training Loss: 2.296, Validation Accuracy: 14.01%\n",
            "Epoch [8/10], Training Loss: 2.293, Validation Accuracy: 13.91%\n",
            "Epoch [9/10], Training Loss: 2.289, Validation Accuracy: 14.00%\n",
            "Epoch [10/10], Training Loss: 2.283, Validation Accuracy: 13.79%\n",
            "Epoch [1/10], Training Loss: 2.277, Validation Accuracy: 13.27%\n",
            "Epoch [2/10], Training Loss: 2.266, Validation Accuracy: 12.83%\n",
            "Epoch [3/10], Training Loss: 2.252, Validation Accuracy: 13.91%\n",
            "Epoch [4/10], Training Loss: 2.238, Validation Accuracy: 17.66%\n",
            "Epoch [5/10], Training Loss: 2.223, Validation Accuracy: 19.91%\n",
            "Epoch [6/10], Training Loss: 2.207, Validation Accuracy: 21.53%\n",
            "Epoch [7/10], Training Loss: 2.191, Validation Accuracy: 22.53%\n",
            "Epoch [8/10], Training Loss: 2.175, Validation Accuracy: 22.79%\n",
            "Epoch [9/10], Training Loss: 2.158, Validation Accuracy: 23.65%\n",
            "Epoch [10/10], Training Loss: 2.141, Validation Accuracy: 24.38%\n",
            "Epoch [1/10], Training Loss: 2.117, Validation Accuracy: 24.63%\n",
            "Epoch [2/10], Training Loss: 2.099, Validation Accuracy: 25.14%\n",
            "Epoch [3/10], Training Loss: 2.080, Validation Accuracy: 25.70%\n",
            "Epoch [4/10], Training Loss: 2.062, Validation Accuracy: 26.02%\n",
            "Epoch [5/10], Training Loss: 2.043, Validation Accuracy: 26.59%\n",
            "Epoch [6/10], Training Loss: 2.027, Validation Accuracy: 26.55%\n",
            "Epoch [7/10], Training Loss: 2.012, Validation Accuracy: 26.96%\n",
            "Epoch [8/10], Training Loss: 1.999, Validation Accuracy: 27.10%\n",
            "Epoch [9/10], Training Loss: 1.988, Validation Accuracy: 27.97%\n",
            "Epoch [10/10], Training Loss: 1.972, Validation Accuracy: 28.87%\n",
            "Epoch [1/10], Training Loss: 1.972, Validation Accuracy: 28.66%\n",
            "Epoch [2/10], Training Loss: 1.957, Validation Accuracy: 28.91%\n",
            "Epoch [3/10], Training Loss: 1.941, Validation Accuracy: 29.25%\n",
            "Epoch [4/10], Training Loss: 1.925, Validation Accuracy: 30.35%\n",
            "Epoch [5/10], Training Loss: 1.905, Validation Accuracy: 30.45%\n",
            "Epoch [6/10], Training Loss: 1.886, Validation Accuracy: 31.43%\n",
            "Epoch [7/10], Training Loss: 1.858, Validation Accuracy: 32.13%\n",
            "Epoch [8/10], Training Loss: 1.834, Validation Accuracy: 33.60%\n",
            "Epoch [9/10], Training Loss: 1.803, Validation Accuracy: 33.80%\n",
            "Epoch [10/10], Training Loss: 1.772, Validation Accuracy: 35.14%\n",
            "Epoch [1/10], Training Loss: 1.758, Validation Accuracy: 35.85%\n",
            "Epoch [2/10], Training Loss: 1.733, Validation Accuracy: 37.28%\n",
            "Epoch [3/10], Training Loss: 1.713, Validation Accuracy: 38.00%\n",
            "Epoch [4/10], Training Loss: 1.693, Validation Accuracy: 38.03%\n",
            "Epoch [5/10], Training Loss: 1.676, Validation Accuracy: 38.65%\n",
            "Epoch [6/10], Training Loss: 1.662, Validation Accuracy: 38.35%\n",
            "Epoch [7/10], Training Loss: 1.647, Validation Accuracy: 39.46%\n",
            "Epoch [8/10], Training Loss: 1.633, Validation Accuracy: 40.31%\n",
            "Epoch [9/10], Training Loss: 1.625, Validation Accuracy: 40.52%\n",
            "Epoch [10/10], Training Loss: 1.612, Validation Accuracy: 40.72%\n",
            "Epoch [1/10], Training Loss: 1.642, Validation Accuracy: 40.90%\n",
            "Epoch [2/10], Training Loss: 1.632, Validation Accuracy: 41.90%\n",
            "Epoch [3/10], Training Loss: 1.618, Validation Accuracy: 42.05%\n",
            "Epoch [4/10], Training Loss: 1.607, Validation Accuracy: 41.87%\n",
            "Epoch [5/10], Training Loss: 1.596, Validation Accuracy: 42.15%\n",
            "Epoch [6/10], Training Loss: 1.585, Validation Accuracy: 42.52%\n",
            "Epoch [7/10], Training Loss: 1.574, Validation Accuracy: 42.97%\n",
            "Epoch [8/10], Training Loss: 1.563, Validation Accuracy: 43.37%\n",
            "Epoch [9/10], Training Loss: 1.550, Validation Accuracy: 43.11%\n",
            "Epoch [10/10], Training Loss: 1.550, Validation Accuracy: 43.32%\n",
            "Epoch [1/10], Training Loss: 1.561, Validation Accuracy: 44.07%\n",
            "Epoch [2/10], Training Loss: 1.550, Validation Accuracy: 44.00%\n",
            "Epoch [3/10], Training Loss: 1.536, Validation Accuracy: 44.83%\n",
            "Epoch [4/10], Training Loss: 1.537, Validation Accuracy: 44.62%\n",
            "Epoch [5/10], Training Loss: 1.522, Validation Accuracy: 45.11%\n",
            "Epoch [6/10], Training Loss: 1.513, Validation Accuracy: 44.63%\n",
            "Epoch [7/10], Training Loss: 1.501, Validation Accuracy: 44.93%\n",
            "Epoch [8/10], Training Loss: 1.495, Validation Accuracy: 45.69%\n",
            "Epoch [9/10], Training Loss: 1.487, Validation Accuracy: 45.92%\n",
            "Epoch [10/10], Training Loss: 1.476, Validation Accuracy: 45.87%\n",
            "Epoch [1/10], Training Loss: 1.489, Validation Accuracy: 46.48%\n",
            "Epoch [2/10], Training Loss: 1.472, Validation Accuracy: 46.17%\n",
            "Epoch [3/10], Training Loss: 1.460, Validation Accuracy: 46.50%\n",
            "Epoch [4/10], Training Loss: 1.454, Validation Accuracy: 46.65%\n",
            "Epoch [5/10], Training Loss: 1.446, Validation Accuracy: 47.36%\n",
            "Epoch [6/10], Training Loss: 1.435, Validation Accuracy: 47.43%\n",
            "Epoch [7/10], Training Loss: 1.428, Validation Accuracy: 47.53%\n",
            "Epoch [8/10], Training Loss: 1.422, Validation Accuracy: 47.33%\n",
            "Epoch [9/10], Training Loss: 1.412, Validation Accuracy: 47.36%\n",
            "Epoch [10/10], Training Loss: 1.411, Validation Accuracy: 47.35%\n",
            "Epoch [1/10], Training Loss: 1.454, Validation Accuracy: 47.70%\n",
            "Epoch [2/10], Training Loss: 1.437, Validation Accuracy: 48.20%\n",
            "Epoch [3/10], Training Loss: 1.423, Validation Accuracy: 48.33%\n",
            "Epoch [4/10], Training Loss: 1.420, Validation Accuracy: 47.28%\n",
            "Epoch [5/10], Training Loss: 1.409, Validation Accuracy: 48.79%\n",
            "Epoch [6/10], Training Loss: 1.393, Validation Accuracy: 48.67%\n",
            "Epoch [7/10], Training Loss: 1.390, Validation Accuracy: 49.13%\n",
            "Epoch [8/10], Training Loss: 1.382, Validation Accuracy: 48.66%\n",
            "Epoch [9/10], Training Loss: 1.378, Validation Accuracy: 49.25%\n",
            "Epoch [10/10], Training Loss: 1.362, Validation Accuracy: 49.96%\n",
            "Epoch [1/10], Training Loss: 1.408, Validation Accuracy: 48.70%\n",
            "Epoch [2/10], Training Loss: 1.389, Validation Accuracy: 48.76%\n",
            "Epoch [3/10], Training Loss: 1.378, Validation Accuracy: 50.24%\n",
            "Epoch [4/10], Training Loss: 1.366, Validation Accuracy: 49.96%\n",
            "Epoch [5/10], Training Loss: 1.364, Validation Accuracy: 49.00%\n",
            "Epoch [6/10], Training Loss: 1.351, Validation Accuracy: 50.03%\n",
            "Epoch [7/10], Training Loss: 1.343, Validation Accuracy: 50.07%\n",
            "Epoch [8/10], Training Loss: 1.335, Validation Accuracy: 50.85%\n",
            "Epoch [9/10], Training Loss: 1.331, Validation Accuracy: 50.14%\n",
            "Epoch [10/10], Training Loss: 1.323, Validation Accuracy: 50.86%\n",
            "Epoch [1/10], Training Loss: 1.384, Validation Accuracy: 50.23%\n",
            "Epoch [2/10], Training Loss: 1.366, Validation Accuracy: 51.20%\n",
            "Epoch [3/10], Training Loss: 1.353, Validation Accuracy: 51.16%\n",
            "Epoch [4/10], Training Loss: 1.340, Validation Accuracy: 51.27%\n",
            "Epoch [5/10], Training Loss: 1.336, Validation Accuracy: 51.67%\n",
            "Epoch [6/10], Training Loss: 1.329, Validation Accuracy: 51.72%\n",
            "Epoch [7/10], Training Loss: 1.328, Validation Accuracy: 51.60%\n",
            "Epoch [8/10], Training Loss: 1.319, Validation Accuracy: 51.95%\n",
            "Epoch [9/10], Training Loss: 1.309, Validation Accuracy: 51.55%\n",
            "Epoch [10/10], Training Loss: 1.301, Validation Accuracy: 50.89%\n",
            "Epoch [1/10], Training Loss: 1.346, Validation Accuracy: 51.75%\n",
            "Epoch [2/10], Training Loss: 1.335, Validation Accuracy: 50.98%\n",
            "Epoch [3/10], Training Loss: 1.315, Validation Accuracy: 52.40%\n",
            "Epoch [4/10], Training Loss: 1.303, Validation Accuracy: 52.87%\n",
            "Epoch [5/10], Training Loss: 1.292, Validation Accuracy: 52.82%\n",
            "Epoch [6/10], Training Loss: 1.289, Validation Accuracy: 52.09%\n",
            "Epoch [7/10], Training Loss: 1.277, Validation Accuracy: 52.39%\n",
            "Epoch [8/10], Training Loss: 1.270, Validation Accuracy: 52.09%\n",
            "Epoch [9/10], Training Loss: 1.269, Validation Accuracy: 52.13%\n",
            "Epoch [10/10], Training Loss: 1.252, Validation Accuracy: 51.55%\n",
            "Epoch [1/10], Training Loss: 1.297, Validation Accuracy: 52.27%\n",
            "Epoch [2/10], Training Loss: 1.281, Validation Accuracy: 53.40%\n",
            "Epoch [3/10], Training Loss: 1.264, Validation Accuracy: 53.83%\n",
            "Epoch [4/10], Training Loss: 1.248, Validation Accuracy: 53.92%\n",
            "Epoch [5/10], Training Loss: 1.237, Validation Accuracy: 53.46%\n",
            "Epoch [6/10], Training Loss: 1.231, Validation Accuracy: 53.62%\n",
            "Epoch [7/10], Training Loss: 1.229, Validation Accuracy: 53.28%\n",
            "Epoch [8/10], Training Loss: 1.210, Validation Accuracy: 53.69%\n",
            "Epoch [9/10], Training Loss: 1.206, Validation Accuracy: 53.16%\n",
            "Epoch [10/10], Training Loss: 1.199, Validation Accuracy: 54.01%\n",
            "Epoch [1/10], Training Loss: 1.292, Validation Accuracy: 53.90%\n",
            "Epoch [2/10], Training Loss: 1.265, Validation Accuracy: 54.15%\n",
            "Epoch [3/10], Training Loss: 1.245, Validation Accuracy: 53.78%\n",
            "Epoch [4/10], Training Loss: 1.238, Validation Accuracy: 53.90%\n",
            "Epoch [5/10], Training Loss: 1.226, Validation Accuracy: 53.88%\n",
            "Epoch [6/10], Training Loss: 1.225, Validation Accuracy: 53.55%\n",
            "Epoch [7/10], Training Loss: 1.211, Validation Accuracy: 53.30%\n",
            "Epoch [8/10], Training Loss: 1.204, Validation Accuracy: 54.63%\n",
            "Epoch [9/10], Training Loss: 1.195, Validation Accuracy: 54.37%\n",
            "Epoch [10/10], Training Loss: 1.194, Validation Accuracy: 53.97%\n",
            "Epoch [1/10], Training Loss: 1.269, Validation Accuracy: 55.10%\n",
            "Epoch [2/10], Training Loss: 1.241, Validation Accuracy: 55.09%\n",
            "Epoch [3/10], Training Loss: 1.218, Validation Accuracy: 55.24%\n",
            "Epoch [4/10], Training Loss: 1.207, Validation Accuracy: 55.25%\n",
            "Epoch [5/10], Training Loss: 1.202, Validation Accuracy: 55.26%\n",
            "Epoch [6/10], Training Loss: 1.187, Validation Accuracy: 55.04%\n",
            "Epoch [7/10], Training Loss: 1.179, Validation Accuracy: 55.71%\n",
            "Epoch [8/10], Training Loss: 1.169, Validation Accuracy: 54.56%\n",
            "Epoch [9/10], Training Loss: 1.160, Validation Accuracy: 55.43%\n",
            "Epoch [10/10], Training Loss: 1.143, Validation Accuracy: 55.84%\n",
            "Epoch [1/10], Training Loss: 1.252, Validation Accuracy: 55.27%\n",
            "Epoch [2/10], Training Loss: 1.230, Validation Accuracy: 55.98%\n",
            "Epoch [3/10], Training Loss: 1.214, Validation Accuracy: 55.73%\n",
            "Epoch [4/10], Training Loss: 1.197, Validation Accuracy: 56.09%\n",
            "Epoch [5/10], Training Loss: 1.188, Validation Accuracy: 55.57%\n",
            "Epoch [6/10], Training Loss: 1.173, Validation Accuracy: 56.29%\n",
            "Epoch [7/10], Training Loss: 1.164, Validation Accuracy: 56.55%\n",
            "Epoch [8/10], Training Loss: 1.152, Validation Accuracy: 55.85%\n",
            "Epoch [9/10], Training Loss: 1.147, Validation Accuracy: 56.20%\n",
            "Epoch [10/10], Training Loss: 1.141, Validation Accuracy: 56.25%\n",
            "Epoch [1/10], Training Loss: 1.226, Validation Accuracy: 56.06%\n",
            "Epoch [2/10], Training Loss: 1.197, Validation Accuracy: 56.66%\n",
            "Epoch [3/10], Training Loss: 1.175, Validation Accuracy: 56.55%\n",
            "Epoch [4/10], Training Loss: 1.163, Validation Accuracy: 57.18%\n",
            "Epoch [5/10], Training Loss: 1.162, Validation Accuracy: 56.91%\n",
            "Epoch [6/10], Training Loss: 1.136, Validation Accuracy: 56.64%\n",
            "Epoch [7/10], Training Loss: 1.131, Validation Accuracy: 56.23%\n",
            "Epoch [8/10], Training Loss: 1.111, Validation Accuracy: 56.29%\n",
            "Epoch [9/10], Training Loss: 1.107, Validation Accuracy: 56.45%\n",
            "Epoch [10/10], Training Loss: 1.096, Validation Accuracy: 56.97%\n",
            "Epoch [1/10], Training Loss: 1.191, Validation Accuracy: 55.55%\n",
            "Epoch [2/10], Training Loss: 1.153, Validation Accuracy: 56.56%\n",
            "Epoch [3/10], Training Loss: 1.136, Validation Accuracy: 57.60%\n",
            "Epoch [4/10], Training Loss: 1.116, Validation Accuracy: 56.96%\n",
            "Epoch [5/10], Training Loss: 1.098, Validation Accuracy: 57.87%\n",
            "Epoch [6/10], Training Loss: 1.092, Validation Accuracy: 57.47%\n",
            "Epoch [7/10], Training Loss: 1.071, Validation Accuracy: 57.73%\n",
            "Epoch [8/10], Training Loss: 1.069, Validation Accuracy: 57.62%\n",
            "Epoch [9/10], Training Loss: 1.059, Validation Accuracy: 57.71%\n",
            "Epoch [10/10], Training Loss: 1.051, Validation Accuracy: 57.70%\n",
            "Epoch [1/10], Training Loss: 1.173, Validation Accuracy: 57.37%\n",
            "Epoch [2/10], Training Loss: 1.133, Validation Accuracy: 57.23%\n",
            "Epoch [3/10], Training Loss: 1.116, Validation Accuracy: 57.59%\n",
            "Epoch [4/10], Training Loss: 1.101, Validation Accuracy: 57.46%\n",
            "Epoch [5/10], Training Loss: 1.082, Validation Accuracy: 57.88%\n",
            "Epoch [6/10], Training Loss: 1.078, Validation Accuracy: 58.01%\n",
            "Epoch [7/10], Training Loss: 1.060, Validation Accuracy: 57.32%\n",
            "Epoch [8/10], Training Loss: 1.051, Validation Accuracy: 57.79%\n",
            "Epoch [9/10], Training Loss: 1.037, Validation Accuracy: 58.04%\n",
            "Epoch [10/10], Training Loss: 1.027, Validation Accuracy: 56.72%\n",
            "Epoch [1/10], Training Loss: 1.156, Validation Accuracy: 58.30%\n",
            "Epoch [2/10], Training Loss: 1.118, Validation Accuracy: 58.03%\n",
            "Epoch [3/10], Training Loss: 1.102, Validation Accuracy: 58.25%\n",
            "Epoch [4/10], Training Loss: 1.083, Validation Accuracy: 56.87%\n",
            "Epoch [5/10], Training Loss: 1.070, Validation Accuracy: 58.33%\n",
            "Epoch [6/10], Training Loss: 1.059, Validation Accuracy: 58.56%\n",
            "Epoch [7/10], Training Loss: 1.052, Validation Accuracy: 58.13%\n",
            "Epoch [8/10], Training Loss: 1.029, Validation Accuracy: 58.35%\n",
            "Epoch [9/10], Training Loss: 1.017, Validation Accuracy: 58.17%\n",
            "Epoch [10/10], Training Loss: 1.009, Validation Accuracy: 58.34%\n",
            "Epoch [1/10], Training Loss: 1.164, Validation Accuracy: 59.02%\n",
            "Epoch [2/10], Training Loss: 1.128, Validation Accuracy: 59.07%\n",
            "Epoch [3/10], Training Loss: 1.099, Validation Accuracy: 58.47%\n",
            "Epoch [4/10], Training Loss: 1.085, Validation Accuracy: 59.18%\n",
            "Epoch [5/10], Training Loss: 1.066, Validation Accuracy: 58.67%\n",
            "Epoch [6/10], Training Loss: 1.054, Validation Accuracy: 59.25%\n",
            "Epoch [7/10], Training Loss: 1.040, Validation Accuracy: 59.10%\n",
            "Epoch [8/10], Training Loss: 1.032, Validation Accuracy: 59.20%\n",
            "Epoch [9/10], Training Loss: 1.018, Validation Accuracy: 58.43%\n",
            "Epoch [10/10], Training Loss: 1.013, Validation Accuracy: 59.18%\n",
            "Epoch [1/10], Training Loss: 1.143, Validation Accuracy: 59.37%\n",
            "Epoch [2/10], Training Loss: 1.088, Validation Accuracy: 59.35%\n",
            "Epoch [3/10], Training Loss: 1.068, Validation Accuracy: 58.84%\n",
            "Epoch [4/10], Training Loss: 1.047, Validation Accuracy: 59.13%\n",
            "Epoch [5/10], Training Loss: 1.041, Validation Accuracy: 59.29%\n",
            "Epoch [6/10], Training Loss: 1.017, Validation Accuracy: 59.05%\n",
            "Epoch [7/10], Training Loss: 1.002, Validation Accuracy: 59.34%\n",
            "Epoch [8/10], Training Loss: 1.000, Validation Accuracy: 58.81%\n",
            "Epoch [9/10], Training Loss: 0.989, Validation Accuracy: 59.13%\n",
            "Epoch [10/10], Training Loss: 0.968, Validation Accuracy: 58.72%\n",
            "Epoch [1/10], Training Loss: 1.092, Validation Accuracy: 59.33%\n",
            "Epoch [2/10], Training Loss: 1.055, Validation Accuracy: 58.76%\n",
            "Epoch [3/10], Training Loss: 1.046, Validation Accuracy: 59.57%\n",
            "Epoch [4/10], Training Loss: 1.009, Validation Accuracy: 59.77%\n",
            "Epoch [5/10], Training Loss: 0.990, Validation Accuracy: 59.29%\n",
            "Epoch [6/10], Training Loss: 0.972, Validation Accuracy: 59.41%\n",
            "Epoch [7/10], Training Loss: 0.963, Validation Accuracy: 58.91%\n",
            "Epoch [8/10], Training Loss: 0.944, Validation Accuracy: 59.80%\n",
            "Epoch [9/10], Training Loss: 0.933, Validation Accuracy: 59.17%\n",
            "Epoch [10/10], Training Loss: 0.925, Validation Accuracy: 59.56%\n",
            "Epoch [1/10], Training Loss: 1.093, Validation Accuracy: 59.91%\n",
            "Epoch [2/10], Training Loss: 1.030, Validation Accuracy: 59.64%\n",
            "Epoch [3/10], Training Loss: 1.010, Validation Accuracy: 58.93%\n",
            "Epoch [4/10], Training Loss: 0.999, Validation Accuracy: 58.81%\n",
            "Epoch [5/10], Training Loss: 0.976, Validation Accuracy: 60.16%\n",
            "Epoch [6/10], Training Loss: 0.960, Validation Accuracy: 59.59%\n",
            "Epoch [7/10], Training Loss: 0.944, Validation Accuracy: 59.91%\n",
            "Epoch [8/10], Training Loss: 0.932, Validation Accuracy: 59.17%\n",
            "Epoch [9/10], Training Loss: 0.920, Validation Accuracy: 60.03%\n",
            "Epoch [10/10], Training Loss: 0.905, Validation Accuracy: 58.83%\n",
            "Epoch [1/10], Training Loss: 1.081, Validation Accuracy: 60.13%\n",
            "Epoch [2/10], Training Loss: 1.035, Validation Accuracy: 59.84%\n",
            "Epoch [3/10], Training Loss: 1.003, Validation Accuracy: 60.48%\n",
            "Epoch [4/10], Training Loss: 0.982, Validation Accuracy: 60.05%\n",
            "Epoch [5/10], Training Loss: 0.964, Validation Accuracy: 60.09%\n",
            "Epoch [6/10], Training Loss: 0.953, Validation Accuracy: 60.02%\n",
            "Epoch [7/10], Training Loss: 0.933, Validation Accuracy: 60.07%\n",
            "Epoch [8/10], Training Loss: 0.915, Validation Accuracy: 60.27%\n",
            "Epoch [9/10], Training Loss: 0.906, Validation Accuracy: 59.99%\n",
            "Epoch [10/10], Training Loss: 0.891, Validation Accuracy: 59.68%\n",
            "Epoch [1/10], Training Loss: 1.079, Validation Accuracy: 59.71%\n",
            "Epoch [2/10], Training Loss: 1.034, Validation Accuracy: 60.45%\n",
            "Epoch [3/10], Training Loss: 1.010, Validation Accuracy: 60.26%\n",
            "Epoch [4/10], Training Loss: 0.976, Validation Accuracy: 60.80%\n",
            "Epoch [5/10], Training Loss: 0.965, Validation Accuracy: 60.59%\n",
            "Epoch [6/10], Training Loss: 0.951, Validation Accuracy: 60.27%\n",
            "Epoch [7/10], Training Loss: 0.936, Validation Accuracy: 59.56%\n",
            "Epoch [8/10], Training Loss: 0.916, Validation Accuracy: 60.27%\n",
            "Epoch [9/10], Training Loss: 0.913, Validation Accuracy: 59.23%\n",
            "Epoch [10/10], Training Loss: 0.892, Validation Accuracy: 60.44%\n",
            "Epoch [1/10], Training Loss: 1.054, Validation Accuracy: 59.74%\n",
            "Epoch [2/10], Training Loss: 1.011, Validation Accuracy: 61.36%\n",
            "Epoch [3/10], Training Loss: 0.974, Validation Accuracy: 60.40%\n",
            "Epoch [4/10], Training Loss: 0.950, Validation Accuracy: 60.56%\n",
            "Epoch [5/10], Training Loss: 0.928, Validation Accuracy: 60.71%\n",
            "Epoch [6/10], Training Loss: 0.913, Validation Accuracy: 60.50%\n",
            "Epoch [7/10], Training Loss: 0.901, Validation Accuracy: 60.42%\n",
            "Epoch [8/10], Training Loss: 0.894, Validation Accuracy: 59.78%\n",
            "Epoch [9/10], Training Loss: 0.878, Validation Accuracy: 60.64%\n",
            "Epoch [10/10], Training Loss: 0.866, Validation Accuracy: 60.41%\n",
            "Epoch [1/10], Training Loss: 1.018, Validation Accuracy: 60.28%\n",
            "Epoch [2/10], Training Loss: 0.965, Validation Accuracy: 60.59%\n",
            "Epoch [3/10], Training Loss: 0.938, Validation Accuracy: 61.11%\n",
            "Epoch [4/10], Training Loss: 0.912, Validation Accuracy: 61.15%\n",
            "Epoch [5/10], Training Loss: 0.894, Validation Accuracy: 60.49%\n",
            "Epoch [6/10], Training Loss: 0.876, Validation Accuracy: 60.93%\n",
            "Epoch [7/10], Training Loss: 0.859, Validation Accuracy: 60.73%\n",
            "Epoch [8/10], Training Loss: 0.843, Validation Accuracy: 61.23%\n",
            "Epoch [9/10], Training Loss: 0.830, Validation Accuracy: 60.82%\n",
            "Epoch [10/10], Training Loss: 0.821, Validation Accuracy: 61.01%\n",
            "Epoch [1/10], Training Loss: 0.993, Validation Accuracy: 61.21%\n",
            "Epoch [2/10], Training Loss: 0.953, Validation Accuracy: 60.16%\n",
            "Epoch [3/10], Training Loss: 0.920, Validation Accuracy: 60.88%\n",
            "Epoch [4/10], Training Loss: 0.897, Validation Accuracy: 61.74%\n",
            "Epoch [5/10], Training Loss: 0.871, Validation Accuracy: 60.92%\n",
            "Epoch [6/10], Training Loss: 0.853, Validation Accuracy: 61.29%\n",
            "Epoch [7/10], Training Loss: 0.838, Validation Accuracy: 61.30%\n",
            "Epoch [8/10], Training Loss: 0.824, Validation Accuracy: 61.05%\n",
            "Epoch [9/10], Training Loss: 0.810, Validation Accuracy: 61.39%\n",
            "Epoch [10/10], Training Loss: 0.790, Validation Accuracy: 61.05%\n",
            "Epoch [1/10], Training Loss: 0.998, Validation Accuracy: 60.21%\n",
            "Epoch [2/10], Training Loss: 0.948, Validation Accuracy: 60.45%\n",
            "Epoch [3/10], Training Loss: 0.917, Validation Accuracy: 61.45%\n",
            "Epoch [4/10], Training Loss: 0.889, Validation Accuracy: 60.51%\n",
            "Epoch [5/10], Training Loss: 0.872, Validation Accuracy: 61.24%\n",
            "Epoch [6/10], Training Loss: 0.849, Validation Accuracy: 61.37%\n",
            "Epoch [7/10], Training Loss: 0.836, Validation Accuracy: 61.12%\n",
            "Epoch [8/10], Training Loss: 0.815, Validation Accuracy: 60.15%\n",
            "Epoch [9/10], Training Loss: 0.804, Validation Accuracy: 60.69%\n",
            "Epoch [10/10], Training Loss: 0.785, Validation Accuracy: 61.10%\n",
            "Epoch [1/10], Training Loss: 1.010, Validation Accuracy: 60.88%\n",
            "Epoch [2/10], Training Loss: 0.962, Validation Accuracy: 60.86%\n",
            "Epoch [3/10], Training Loss: 0.919, Validation Accuracy: 61.22%\n",
            "Epoch [4/10], Training Loss: 0.896, Validation Accuracy: 60.79%\n",
            "Epoch [5/10], Training Loss: 0.879, Validation Accuracy: 60.90%\n",
            "Epoch [6/10], Training Loss: 0.851, Validation Accuracy: 60.87%\n",
            "Epoch [7/10], Training Loss: 0.838, Validation Accuracy: 61.64%\n",
            "Epoch [8/10], Training Loss: 0.823, Validation Accuracy: 61.08%\n",
            "Epoch [9/10], Training Loss: 0.808, Validation Accuracy: 61.12%\n",
            "Epoch [10/10], Training Loss: 0.791, Validation Accuracy: 60.97%\n",
            "Epoch [1/10], Training Loss: 0.982, Validation Accuracy: 61.30%\n",
            "Epoch [2/10], Training Loss: 0.921, Validation Accuracy: 61.35%\n",
            "Epoch [3/10], Training Loss: 0.889, Validation Accuracy: 60.71%\n",
            "Epoch [4/10], Training Loss: 0.872, Validation Accuracy: 61.10%\n",
            "Epoch [5/10], Training Loss: 0.843, Validation Accuracy: 60.55%\n",
            "Epoch [6/10], Training Loss: 0.822, Validation Accuracy: 61.32%\n",
            "Epoch [7/10], Training Loss: 0.802, Validation Accuracy: 60.91%\n",
            "Epoch [8/10], Training Loss: 0.791, Validation Accuracy: 61.14%\n",
            "Epoch [9/10], Training Loss: 0.776, Validation Accuracy: 61.49%\n",
            "Epoch [10/10], Training Loss: 0.756, Validation Accuracy: 60.80%\n",
            "Epoch [1/10], Training Loss: 0.952, Validation Accuracy: 61.74%\n",
            "Epoch [2/10], Training Loss: 0.898, Validation Accuracy: 61.35%\n",
            "Epoch [3/10], Training Loss: 0.859, Validation Accuracy: 61.63%\n",
            "Epoch [4/10], Training Loss: 0.833, Validation Accuracy: 61.73%\n",
            "Epoch [5/10], Training Loss: 0.808, Validation Accuracy: 62.19%\n",
            "Epoch [6/10], Training Loss: 0.786, Validation Accuracy: 61.67%\n",
            "Epoch [7/10], Training Loss: 0.769, Validation Accuracy: 61.65%\n",
            "Epoch [8/10], Training Loss: 0.751, Validation Accuracy: 61.30%\n",
            "Epoch [9/10], Training Loss: 0.741, Validation Accuracy: 61.76%\n",
            "Epoch [10/10], Training Loss: 0.726, Validation Accuracy: 61.24%\n",
            "Epoch [1/10], Training Loss: 0.935, Validation Accuracy: 61.85%\n",
            "Epoch [2/10], Training Loss: 0.875, Validation Accuracy: 61.58%\n",
            "Epoch [3/10], Training Loss: 0.840, Validation Accuracy: 62.15%\n",
            "Epoch [4/10], Training Loss: 0.806, Validation Accuracy: 61.47%\n",
            "Epoch [5/10], Training Loss: 0.777, Validation Accuracy: 61.39%\n",
            "Epoch [6/10], Training Loss: 0.764, Validation Accuracy: 61.28%\n",
            "Epoch [7/10], Training Loss: 0.758, Validation Accuracy: 61.34%\n",
            "Epoch [8/10], Training Loss: 0.726, Validation Accuracy: 61.61%\n",
            "Epoch [9/10], Training Loss: 0.707, Validation Accuracy: 61.43%\n",
            "Epoch [10/10], Training Loss: 0.700, Validation Accuracy: 60.75%\n",
            "Epoch [1/10], Training Loss: 0.949, Validation Accuracy: 61.90%\n",
            "Epoch [2/10], Training Loss: 0.876, Validation Accuracy: 62.02%\n",
            "Epoch [3/10], Training Loss: 0.838, Validation Accuracy: 61.83%\n",
            "Epoch [4/10], Training Loss: 0.799, Validation Accuracy: 60.93%\n",
            "Epoch [5/10], Training Loss: 0.781, Validation Accuracy: 60.64%\n",
            "Epoch [6/10], Training Loss: 0.754, Validation Accuracy: 61.09%\n",
            "Epoch [7/10], Training Loss: 0.745, Validation Accuracy: 61.76%\n",
            "Epoch [8/10], Training Loss: 0.720, Validation Accuracy: 61.08%\n",
            "Epoch [9/10], Training Loss: 0.699, Validation Accuracy: 60.62%\n",
            "Epoch [10/10], Training Loss: 0.688, Validation Accuracy: 61.25%\n",
            "Epoch [1/10], Training Loss: 0.966, Validation Accuracy: 60.97%\n",
            "Epoch [2/10], Training Loss: 0.887, Validation Accuracy: 61.22%\n",
            "Epoch [3/10], Training Loss: 0.843, Validation Accuracy: 61.04%\n",
            "Epoch [4/10], Training Loss: 0.816, Validation Accuracy: 62.02%\n",
            "Epoch [5/10], Training Loss: 0.803, Validation Accuracy: 61.85%\n",
            "Epoch [6/10], Training Loss: 0.769, Validation Accuracy: 61.03%\n",
            "Epoch [7/10], Training Loss: 0.741, Validation Accuracy: 61.63%\n",
            "Epoch [8/10], Training Loss: 0.733, Validation Accuracy: 60.90%\n",
            "Epoch [9/10], Training Loss: 0.714, Validation Accuracy: 61.38%\n",
            "Epoch [10/10], Training Loss: 0.694, Validation Accuracy: 61.51%\n",
            "Epoch [1/10], Training Loss: 0.929, Validation Accuracy: 61.84%\n",
            "Epoch [2/10], Training Loss: 0.855, Validation Accuracy: 61.17%\n",
            "Epoch [3/10], Training Loss: 0.808, Validation Accuracy: 62.13%\n",
            "Epoch [4/10], Training Loss: 0.786, Validation Accuracy: 62.23%\n",
            "Epoch [5/10], Training Loss: 0.754, Validation Accuracy: 61.48%\n",
            "Epoch [6/10], Training Loss: 0.739, Validation Accuracy: 62.10%\n",
            "Epoch [7/10], Training Loss: 0.709, Validation Accuracy: 61.91%\n",
            "Epoch [8/10], Training Loss: 0.697, Validation Accuracy: 61.51%\n",
            "Epoch [9/10], Training Loss: 0.689, Validation Accuracy: 61.61%\n",
            "Epoch [10/10], Training Loss: 0.675, Validation Accuracy: 60.66%\n",
            "Epoch [1/10], Training Loss: 0.896, Validation Accuracy: 61.87%\n",
            "Epoch [2/10], Training Loss: 0.840, Validation Accuracy: 61.35%\n",
            "Epoch [3/10], Training Loss: 0.781, Validation Accuracy: 62.25%\n",
            "Epoch [4/10], Training Loss: 0.763, Validation Accuracy: 61.85%\n",
            "Epoch [5/10], Training Loss: 0.725, Validation Accuracy: 61.76%\n",
            "Epoch [6/10], Training Loss: 0.707, Validation Accuracy: 62.36%\n",
            "Epoch [7/10], Training Loss: 0.679, Validation Accuracy: 61.54%\n",
            "Epoch [8/10], Training Loss: 0.670, Validation Accuracy: 62.04%\n",
            "Epoch [9/10], Training Loss: 0.648, Validation Accuracy: 61.69%\n",
            "Epoch [10/10], Training Loss: 0.640, Validation Accuracy: 62.01%\n",
            "Epoch [1/10], Training Loss: 0.891, Validation Accuracy: 61.43%\n",
            "Epoch [2/10], Training Loss: 0.825, Validation Accuracy: 61.74%\n",
            "Epoch [3/10], Training Loss: 0.765, Validation Accuracy: 61.51%\n",
            "Epoch [4/10], Training Loss: 0.734, Validation Accuracy: 61.67%\n",
            "Epoch [5/10], Training Loss: 0.697, Validation Accuracy: 62.22%\n",
            "Epoch [6/10], Training Loss: 0.669, Validation Accuracy: 62.15%\n",
            "Epoch [7/10], Training Loss: 0.646, Validation Accuracy: 61.15%\n",
            "Epoch [8/10], Training Loss: 0.636, Validation Accuracy: 61.71%\n",
            "Epoch [9/10], Training Loss: 0.610, Validation Accuracy: 61.22%\n",
            "Epoch [10/10], Training Loss: 0.595, Validation Accuracy: 61.13%\n",
            "Epoch [1/10], Training Loss: 0.897, Validation Accuracy: 61.06%\n",
            "Epoch [2/10], Training Loss: 0.801, Validation Accuracy: 61.99%\n",
            "Epoch [3/10], Training Loss: 0.743, Validation Accuracy: 61.72%\n",
            "Epoch [4/10], Training Loss: 0.712, Validation Accuracy: 62.26%\n",
            "Epoch [5/10], Training Loss: 0.682, Validation Accuracy: 61.57%\n",
            "Epoch [6/10], Training Loss: 0.667, Validation Accuracy: 62.03%\n",
            "Epoch [7/10], Training Loss: 0.639, Validation Accuracy: 61.58%\n",
            "Epoch [8/10], Training Loss: 0.624, Validation Accuracy: 61.64%\n",
            "Epoch [9/10], Training Loss: 0.605, Validation Accuracy: 61.42%\n",
            "Epoch [10/10], Training Loss: 0.581, Validation Accuracy: 61.17%\n",
            "Epoch [1/10], Training Loss: 0.919, Validation Accuracy: 61.58%\n",
            "Epoch [2/10], Training Loss: 0.822, Validation Accuracy: 61.08%\n",
            "Epoch [3/10], Training Loss: 0.777, Validation Accuracy: 62.18%\n",
            "Epoch [4/10], Training Loss: 0.733, Validation Accuracy: 62.44%\n",
            "Epoch [5/10], Training Loss: 0.703, Validation Accuracy: 62.31%\n",
            "Epoch [6/10], Training Loss: 0.677, Validation Accuracy: 61.42%\n",
            "Epoch [7/10], Training Loss: 0.652, Validation Accuracy: 61.68%\n",
            "Epoch [8/10], Training Loss: 0.642, Validation Accuracy: 61.72%\n",
            "Epoch [9/10], Training Loss: 0.612, Validation Accuracy: 61.21%\n",
            "Epoch [10/10], Training Loss: 0.603, Validation Accuracy: 61.14%\n",
            "Epoch [1/10], Training Loss: 0.881, Validation Accuracy: 62.59%\n",
            "Epoch [2/10], Training Loss: 0.782, Validation Accuracy: 62.28%\n",
            "Epoch [3/10], Training Loss: 0.736, Validation Accuracy: 62.61%\n",
            "Epoch [4/10], Training Loss: 0.701, Validation Accuracy: 62.30%\n",
            "Epoch [5/10], Training Loss: 0.671, Validation Accuracy: 61.33%\n",
            "Epoch [6/10], Training Loss: 0.641, Validation Accuracy: 61.98%\n",
            "Epoch [7/10], Training Loss: 0.630, Validation Accuracy: 62.05%\n",
            "Epoch [8/10], Training Loss: 0.609, Validation Accuracy: 61.84%\n",
            "Epoch [9/10], Training Loss: 0.583, Validation Accuracy: 61.85%\n",
            "Epoch [10/10], Training Loss: 0.577, Validation Accuracy: 61.77%\n",
            "Epoch [1/10], Training Loss: 0.851, Validation Accuracy: 61.09%\n",
            "Epoch [2/10], Training Loss: 0.777, Validation Accuracy: 62.28%\n",
            "Epoch [3/10], Training Loss: 0.716, Validation Accuracy: 62.06%\n",
            "Epoch [4/10], Training Loss: 0.676, Validation Accuracy: 62.02%\n",
            "Epoch [5/10], Training Loss: 0.646, Validation Accuracy: 62.33%\n",
            "Epoch [6/10], Training Loss: 0.621, Validation Accuracy: 61.74%\n",
            "Epoch [7/10], Training Loss: 0.590, Validation Accuracy: 61.71%\n",
            "Epoch [8/10], Training Loss: 0.568, Validation Accuracy: 61.69%\n",
            "Epoch [9/10], Training Loss: 0.561, Validation Accuracy: 61.75%\n",
            "Epoch [10/10], Training Loss: 0.537, Validation Accuracy: 61.77%\n",
            "Epoch [1/10], Training Loss: 0.849, Validation Accuracy: 61.68%\n",
            "Epoch [2/10], Training Loss: 0.747, Validation Accuracy: 61.78%\n",
            "Epoch [3/10], Training Loss: 0.686, Validation Accuracy: 61.84%\n",
            "Epoch [4/10], Training Loss: 0.657, Validation Accuracy: 61.66%\n",
            "Epoch [5/10], Training Loss: 0.609, Validation Accuracy: 61.78%\n",
            "Epoch [6/10], Training Loss: 0.589, Validation Accuracy: 61.99%\n",
            "Epoch [7/10], Training Loss: 0.573, Validation Accuracy: 61.70%\n",
            "Epoch [8/10], Training Loss: 0.534, Validation Accuracy: 61.75%\n",
            "Epoch [9/10], Training Loss: 0.520, Validation Accuracy: 61.74%\n",
            "Epoch [10/10], Training Loss: 0.508, Validation Accuracy: 61.84%\n",
            "Epoch [1/10], Training Loss: 0.854, Validation Accuracy: 61.39%\n",
            "Epoch [2/10], Training Loss: 0.738, Validation Accuracy: 61.93%\n",
            "Epoch [3/10], Training Loss: 0.677, Validation Accuracy: 61.66%\n",
            "Epoch [4/10], Training Loss: 0.645, Validation Accuracy: 61.72%\n",
            "Epoch [5/10], Training Loss: 0.608, Validation Accuracy: 61.69%\n",
            "Epoch [6/10], Training Loss: 0.582, Validation Accuracy: 61.61%\n",
            "Epoch [7/10], Training Loss: 0.552, Validation Accuracy: 61.44%\n",
            "Epoch [8/10], Training Loss: 0.531, Validation Accuracy: 62.03%\n",
            "Epoch [9/10], Training Loss: 0.507, Validation Accuracy: 61.52%\n",
            "Epoch [10/10], Training Loss: 0.491, Validation Accuracy: 61.66%\n",
            "Epoch [1/10], Training Loss: 0.873, Validation Accuracy: 61.97%\n",
            "Epoch [2/10], Training Loss: 0.760, Validation Accuracy: 61.31%\n",
            "Epoch [3/10], Training Loss: 0.696, Validation Accuracy: 60.67%\n",
            "Epoch [4/10], Training Loss: 0.660, Validation Accuracy: 61.48%\n",
            "Epoch [5/10], Training Loss: 0.631, Validation Accuracy: 61.38%\n",
            "Epoch [6/10], Training Loss: 0.602, Validation Accuracy: 61.43%\n",
            "Epoch [7/10], Training Loss: 0.570, Validation Accuracy: 61.67%\n",
            "Epoch [8/10], Training Loss: 0.550, Validation Accuracy: 61.58%\n",
            "Epoch [9/10], Training Loss: 0.525, Validation Accuracy: 61.64%\n",
            "Epoch [10/10], Training Loss: 0.506, Validation Accuracy: 59.88%\n",
            "Epoch [1/10], Training Loss: 0.843, Validation Accuracy: 62.06%\n",
            "Epoch [2/10], Training Loss: 0.728, Validation Accuracy: 61.30%\n",
            "Epoch [3/10], Training Loss: 0.668, Validation Accuracy: 61.91%\n",
            "Epoch [4/10], Training Loss: 0.620, Validation Accuracy: 62.20%\n",
            "Epoch [5/10], Training Loss: 0.591, Validation Accuracy: 61.65%\n",
            "Epoch [6/10], Training Loss: 0.564, Validation Accuracy: 61.63%\n",
            "Epoch [7/10], Training Loss: 0.547, Validation Accuracy: 62.12%\n",
            "Epoch [8/10], Training Loss: 0.516, Validation Accuracy: 61.77%\n",
            "Epoch [9/10], Training Loss: 0.497, Validation Accuracy: 61.48%\n",
            "Epoch [10/10], Training Loss: 0.478, Validation Accuracy: 61.45%\n",
            "Epoch [1/10], Training Loss: 0.817, Validation Accuracy: 61.74%\n",
            "Epoch [2/10], Training Loss: 0.710, Validation Accuracy: 61.62%\n",
            "Epoch [3/10], Training Loss: 0.644, Validation Accuracy: 62.21%\n",
            "Epoch [4/10], Training Loss: 0.603, Validation Accuracy: 61.88%\n",
            "Epoch [5/10], Training Loss: 0.565, Validation Accuracy: 62.22%\n",
            "Epoch [6/10], Training Loss: 0.538, Validation Accuracy: 62.14%\n",
            "Epoch [7/10], Training Loss: 0.514, Validation Accuracy: 61.90%\n",
            "Epoch [8/10], Training Loss: 0.487, Validation Accuracy: 61.67%\n",
            "Epoch [9/10], Training Loss: 0.475, Validation Accuracy: 61.85%\n",
            "Epoch [10/10], Training Loss: 0.448, Validation Accuracy: 61.94%\n",
            "Epoch [1/10], Training Loss: 0.795, Validation Accuracy: 61.25%\n",
            "Epoch [2/10], Training Loss: 0.676, Validation Accuracy: 61.17%\n",
            "Epoch [3/10], Training Loss: 0.616, Validation Accuracy: 61.83%\n",
            "Epoch [4/10], Training Loss: 0.570, Validation Accuracy: 61.27%\n",
            "Epoch [5/10], Training Loss: 0.542, Validation Accuracy: 61.94%\n",
            "Epoch [6/10], Training Loss: 0.497, Validation Accuracy: 61.73%\n",
            "Epoch [7/10], Training Loss: 0.472, Validation Accuracy: 61.32%\n",
            "Epoch [8/10], Training Loss: 0.467, Validation Accuracy: 61.41%\n",
            "Epoch [9/10], Training Loss: 0.434, Validation Accuracy: 61.55%\n",
            "Epoch [10/10], Training Loss: 0.413, Validation Accuracy: 61.54%\n",
            "Epoch [1/10], Training Loss: 0.822, Validation Accuracy: 60.86%\n",
            "Epoch [2/10], Training Loss: 0.681, Validation Accuracy: 61.68%\n",
            "Epoch [3/10], Training Loss: 0.604, Validation Accuracy: 61.75%\n",
            "Epoch [4/10], Training Loss: 0.572, Validation Accuracy: 61.30%\n",
            "Epoch [5/10], Training Loss: 0.526, Validation Accuracy: 61.52%\n",
            "Epoch [6/10], Training Loss: 0.493, Validation Accuracy: 61.72%\n",
            "Epoch [7/10], Training Loss: 0.477, Validation Accuracy: 61.81%\n",
            "Epoch [8/10], Training Loss: 0.446, Validation Accuracy: 61.99%\n",
            "Epoch [9/10], Training Loss: 0.421, Validation Accuracy: 61.62%\n",
            "Epoch [10/10], Training Loss: 0.410, Validation Accuracy: 60.96%\n",
            "Test Accuracy: 61.05%\n",
            "CPU times: user 3h 29min 46s, sys: 1min 25s, total: 3h 31min 11s\n",
            "Wall time: 3h 47min 56s\n"
          ]
        }
      ]
    }
  ]
}